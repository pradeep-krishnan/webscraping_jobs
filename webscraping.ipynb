{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Scraping indeed website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "from time import sleep\n",
    "import urllib.request\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "link = \"http://www.indeed.com/jobs?q=data+scientist+%2420%2C000&l={}&start={}\"\n",
    "max_results_per_city = 1000 # Set this to a high-value (5000) to generate more results. \n",
    "# Crawling more results, will also take much longer. First test your code on a small number of results and then expand.\n",
    "i = 0\n",
    "results = []\n",
    "df1 = pd.DataFrame(columns=[\"Title\",\"Location\",\"Company\",\"Salary\", \"Summary\", \"Description\", \"Review\"])\n",
    "for city in set(['Atlanta', 'Austin', 'Baltimore', 'Boston', 'Charlotte', 'Chicago', 'Cincinnati', 'Columbus', \n",
    "          'Dallas', 'Denver', 'Houston', 'Indianapolis', 'Jacksonville', 'Kansas+City', 'Los+AngelesNew+York', \n",
    "          'Miami', 'Minneapolis', 'Nashville', 'Oakland', 'Philadelphia', 'Phoenix', 'Pittsburgh', 'Portland', \n",
    "          'San+Diego', 'San+Francisco', 'San+Jose', 'Seattle', 'St.+Louis', 'Tampa', 'Washington%2C+DC']):\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        # Grab the results from the request (as above)\n",
    "        url = link.format(city, start)\n",
    "        # Append to the full set of results\n",
    "        html = requests.get(url)\n",
    "        soup = BeautifulSoup(html.content, 'html.parser', from_encoding=\"utf-8\")\n",
    "        for each in soup.find_all(class_= \"result\" ):\n",
    "            try: \n",
    "                title = each.find(class_='jobtitle').text.replace('\\n', '')\n",
    "            except:\n",
    "                title = None\n",
    "            try:\n",
    "                location = each.find('span', {'class':\"location\" }).text.replace('\\n', '')\n",
    "            except:\n",
    "                location = None\n",
    "            try: \n",
    "                company = each.find(class_='company').text.replace('\\n', '')\n",
    "            except:\n",
    "                company = None\n",
    "            try:\n",
    "                salary = each.find('span', {'class':'no-wrap'}).text\n",
    "            except:\n",
    "                salary = None\n",
    "            try:\n",
    "                summary = each.find('span', {'class':'summary'}).text.replace('\\n', '')\n",
    "            except:\n",
    "                summary = None\n",
    "            try: \n",
    "                description_link = (\"%s%s\" % (\"https://www.indeed.com\",each.find('a').get('href')))\n",
    "            except:\n",
    "                description_link = 'None'\n",
    "            try:\n",
    "                review_link = (\"%s%s\" % (\"https://www.indeed.com\",each.find('div').find('a').get('href')))            \n",
    "            except: \n",
    "                review_link = 'None'\n",
    "            df1 = df1.append({'Title':title, 'Location':location, 'Company':company, 'Salary':salary, 'Summary':summary,\\\n",
    "                                      'Description':description_link, 'job_description': None, 'Review': review_link,\\\n",
    "                           'comp_rating_overall': None, 'wl_bal_rating': None, 'benefit_rating': None, 'jsecurity_rating': None,\\\n",
    "                            'mgmt_rating': None, 'culture_rating': None}, ignore_index=True)\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_jobdesc(df):\n",
    "    for i in range(0,len(df)):\n",
    "        company_name = df.iloc[i]['Company']\n",
    "        desc = df.iloc[i]['Description']\n",
    "        html = requests.get(desc)\n",
    "        soup = BeautifulSoup(html.content, 'html.parser', from_encoding=\"utf-8\")\n",
    "        try:\n",
    "            df.loc[df['Company'] == company_name, 'job_description'] = soup.find(class_=\"jobsearch-JobComponent-description icl-u-xs-mt--md\").text.replace('\\n', ' ')\n",
    "        except:\n",
    "            df.loc[df['Company'] == company_name, 'job_description'] = 'None'\n",
    "        sleep(0.10)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_jobdesc_again(df):\n",
    "    for i in range(0,len(df)):\n",
    "        if(df.iloc[i]['job_description'] == 'None'):\n",
    "            company_name = df.iloc[i]['Company']\n",
    "            desc = df.iloc[i]['Description']\n",
    "            html = requests.get(desc)\n",
    "            soup = BeautifulSoup(html.content, 'html.parser', from_encoding=\"utf-8\")\n",
    "            try:\n",
    "                df.loc[df['Company'] == company_name, 'job_description'] = soup.find(class_=\"jobsearch-JobComponent-description icl-u-xs-mt--md\").text.replace('\\n', ' ')\n",
    "            except:\n",
    "                df.loc[df['Company'] == company_name, 'job_description'] = 'None'\n",
    "            sleep(0.10)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_reviews(df):\n",
    "    for i in range(0,len(df)):\n",
    "        if(df.iloc[i]['Review'] != 'None'):\n",
    "            company_name = df.iloc[i]['Company']\n",
    "            cmp_page = df.iloc[i]['Review']\n",
    "            html = requests.get(cmp_page)\n",
    "            soup = BeautifulSoup(html.content, 'html.parser', from_encoding=\"utf-8\")\n",
    "            try:\n",
    "                df.loc[df['Company'] == company_name, 'comp_rating_overall'] = float(soup.find(class_=\"cmp-header-rating-average\").text.replace('\\n', ' '))\n",
    "            except:\n",
    "                df.loc[df['Company'] == company_name, 'comp_rating_overall'] = 'None'\n",
    "            try:\n",
    "                df.loc[df['Company'] == company_name, 'wl_bal_rating'] = float(soup.find(\"div\",{\"class\": \"cmp-ReviewCategory cmp-ReviewCategory--textmd\"}).\\\n",
    "                        find_all(\"span\", {\"class\": \"cmp-ReviewCategory-rating\"})[0].text.replace('\\n', ' '))\n",
    "            except:\n",
    "                df.loc[df['Company'] == company_name, 'wl_bal_rating'] = 'None'\n",
    "            try:\n",
    "                df.loc[df['Company'] == company_name, 'benefit_rating'] = float(soup.find(\"div\",{\"class\": \"cmp-ReviewCategory cmp-ReviewCategory--textmd\"}).\\\n",
    "                        find_all(\"span\", {\"class\": \"cmp-ReviewCategory-rating\"})[1].text.replace('\\n', ' '))\n",
    "            except:\n",
    "                df.loc[df['Company'] == company_name, 'benefit_rating'] = 'None'\n",
    "            try:\n",
    "                df.loc[df['Company'] == company_name, 'jsecurity_rating'] = float(soup.find(\"div\",{\"class\": \"cmp-ReviewCategory cmp-ReviewCategory--textmd\"}).\\\n",
    "                        find_all(\"span\", {\"class\": \"cmp-ReviewCategory-rating\"})[2].text.replace('\\n', ' '))\n",
    "            except:\n",
    "                df.loc[df['Company'] == company_name, 'jsecurity_rating'] = 'None'\n",
    "            try:\n",
    "                df.loc[df['Company'] == company_name, 'mgmt_rating'] = float(soup.find(\"div\",{\"class\": \"cmp-ReviewCategory cmp-ReviewCategory--textmd\"}).\\\n",
    "                        find_all(\"span\", {\"class\": \"cmp-ReviewCategory-rating\"})[3].text.replace('\\n', ' '))\n",
    "            except:\n",
    "                df.loc[df['Company'] == company_name, 'mgmt_rating'] = 'None'\n",
    "            try:\n",
    "                df.loc[df['Company'] == company_name, 'culture_rating'] = float(soup.find(\"div\",{\"class\": \"cmp-ReviewCategory cmp-ReviewCategory--textmd\"}).\\\n",
    "                        find_all(\"span\", {\"class\": \"cmp-ReviewCategory-rating\"})[4].text.replace('\\n', ' '))\n",
    "            except:\n",
    "                df.loc[df['Company'] == company_name, 'culture_rating'] = 'None'\n",
    "            sleep(0.10)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1.to_csv('jobs_desc_ratings.csv', index = False)\n",
    "df1 =  pd.read_csv('jobs_desc_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1_0_0 = get_jobdesc(df1_0)\n",
    "df1_0_1 = get_jobdesc_again(df1_0_0)\n",
    "df1_0_2 = get_reviews(df1_0_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1_0_3.to_csv('job_desc_ratings.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
